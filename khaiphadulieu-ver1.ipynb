{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import re\nimport pickle\nfrom pyvi import ViTokenizer, ViPosTagger # thư viện NLP tiếng Việt\nfrom tqdm import tqdm\nimport numpy as np\nimport gensim # thư viện NLP\nX_data = []\ny_label = []\nwith open('../input/khaiphadulieu/topic_detection_train.v1.0.txt', 'r', encoding=\"utf-8\") as f:\n    for lines in f.readlines():\n        index = lines.find(' ')\n        y_label.append(lines[:index])\n        lines = lines[index:]\n        lines = gensim.utils.simple_preprocess(lines)\n#         lines = re.sub(r\"[^\\w\\d\\s]\",\" \",lines,flags=re.UNICODE)\n#         lines = re.sub(\"[0-9]\",\" \",lines,flags=re.UNICODE)\n#         lines = lines.split()\n        lines = ' '.join(lines)\n        lines = ViTokenizer.tokenize(lines)\n        X_data.append(lines)\npickle.dump(X_data, open('X_data.pkl', 'wb'))\npickle.dump(y_label, open('y_label.pkl', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nX_data = pickle.load(open('X_data.pkl', 'rb'))\ny_label = pickle.load(open('y_label.pkl', 'rb'))\nprint(X_data[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # tạo stopword bằng cách đếm số từ phổ biến\n# uniqueWords = []\n# numOfWords = []\n# for bagOfWords in X_data:\n#     uniqueWords = set(uniqueWords).union(set(bagOfWords.split(' ')))\n# numOfWords = dict.fromkeys(uniqueWords, 0)\n# for bagOfWords in X_data:\n#     for word in set(bagOfWords.split(' ')).union():\n#         numOfWords[word] += bagOfWords.count(word)\n# numOfWords_sorted = sorted(numOfWords.items(), key=lambda item: item[1])\n# i = 0\n# word_stop = []\n# for word in numOfWords_sorted:\n#     print(numOfWords_sorted[len(numOfWords)-1-i])\n#     i+=1\n#     w,num = numOfWords_sorted[len(numOfWords)-1-i]\n#     if w == \"nước\":\n#         break\n#     word_stop.append(w)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #tạo stopword bằng cách liệt kê\n# word_stop = \"ng bị bởi cả các cái cần càng chỉ chiếc cho chứ chưa chuyện có có_thể cứ của cùng cũng đã đang đây để đến_nỗi đều điều do đó được dưới gì khi không là lại lên lúc mà mỗi một_cách này nên nếu ngay nhiều như nhưng những nơi nữa phải qua ra rằng rằng rất rất rồi sau sẽ so sự tại theo thì trên trước từ từng và vẫn vào vậy vì việc với vừa\"\n# word_stop = word_stop.split()\n# pickle.dump(word_stop, open('word_stop.pkl', 'wb'))\n# word_stops = pickle.load(open('word_stop.pkl', 'rb'))\n# for index in range(len(X_data)):\n#     for word_stop in word_stops:\n#         if word_stop in X_data[index]:\n#             X_data[index] = X_data[index].replace(word_stop+' ', '')\n# pickle.dump(X_data, open('X_data.pkl', 'wb'))\n# X_data = pickle.load(open('X_data.pkl', 'rb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#require\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_label, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_vect_ngram_char = TfidfVectorizer(analyzer='char', max_features=30000, ngram_range=(2, 3))\ntfidf_vect_ngram_char.fit(X_train)\nX_data_tfidf_ngram_char =  tfidf_vect_ngram_char.transform(X_train)\n# assume that we don't have test set before\nX_test_tfidf_ngram_char =  tfidf_vect_ngram_char.transform(X_test)\nfrom sklearn.decomposition import TruncatedSVD\nsvd_ngram_char = TruncatedSVD(n_components=300, random_state=42)\nsvd_ngram_char.fit(X_data_tfidf_ngram_char)\n\nX_data_tfidf_ngram_char_svd = svd_ngram_char.transform(X_data_tfidf_ngram_char)\n# assume that we don't have test set before\nX_test_tfidf_ngram_char_svd = svd_ngram_char.transform(X_test_tfidf_ngram_char)\npickle.dump(X_data_tfidf_ngram_char_svd, open('X_data_tfidf_ngram_char_svd.pkl', 'wb'))\npickle.dump(X_test_tfidf_ngram_char_svd, open('X_test_tfidf_ngram_char_svd.pkl', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#require\nfrom sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\ny_data_n = encoder.fit_transform(y_train)\ny_test_n = encoder.fit_transform(y_test)\ny_data_encoder = encoder.fit_transform(y_label)\nencoder.classes_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_vect = TfidfVectorizer(analyzer='word', max_features=30000)\ntfidf_vect.fit(X_train) # learn vocabulary and idf from training set\nX_data_tfidf =  tfidf_vect.transform(X_train)\n# assume that we don't have test set before\nX_test_tfidf =  tfidf_vect.transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ngram level - we choose max number of words equal to 30000 except all words (100k+ words)\ntfidf_vect_ngram = TfidfVectorizer(analyzer='word', max_features=30000, ngram_range=(2, 3))\ntfidf_vect_ngram.fit(X_train)\nX_data_tfidf_ngram =  tfidf_vect_ngram.transform(X_train)\n# assume that we don't have test set before\nX_test_tfidf_ngram =  tfidf_vect_ngram.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#require\nX_data_tfidf_ngram_char_svd = pickle.load(open('X_data_tfidf_ngram_char_svd.pkl', 'rb'))\nX_test_tfidf_ngram_char_svd = pickle.load(open('X_test_tfidf_ngram_char_svd.pkl', 'rb'))\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import neighbors\nimport matplotlib.pyplot as plt\nclf = neighbors.KNeighborsClassifier(n_neighbors = 5, p = 2, weights = 'distance')\nclf.fit(X_data_tfidf_ngram_char_svd, y_data_n)\ny_pred = clf.predict(X_test_tfidf_ngram_char_svd)\nprint(\"Accuracy of KNN: %.2f %%\" %(100*accuracy_score(y_test_n, y_pred)))\n# Save model\npickle.dump(clf, open('neighbors.pkl', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf_logic = LogisticRegression(random_state=0).fit(X_data_tfidf_ngram_char_svd, y_data_n)\ny_pred_logic = clf_logic.predict(X_test_tfidf_ngram_char_svd)\nprint(\"Accuracy of logistic: %.2f %%\" %(100*accuracy_score(y_test_n, y_pred_logic)))\npickle.dump(clf_logic, open('LogisticRegression.pkl', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.gaussian_process import GaussianProcessRegressor\n# from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n# kernel = DotProduct() + WhiteKernel()\n# gpr = GaussianProcessRegressor(kernel=kernel,random_state=0).fit(X_data_tfidf_ngram_char_svd, y_data_n)\n# y_pred_gpr, sigma = gpr.predict(X_test_tfidf_ngram_char_svd, return_std=True)\n# # print(\"Accuracy of KNN: %.2f %%\" %(100*accuracy_score(y_test_n, y_pred_gpr)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.decomposition import TruncatedSVD\n# from sklearn.svm import SVC\n# for n in range(100,3000,100):\n#     svd_ngram_char = TruncatedSVD(n_components=n, random_state=42)\n#     svd_ngram_char.fit(X_data_tfidf_ngram_char)\n\n#     X_data_tfidf_ngram_char_svd = svd_ngram_char.transform(X_data_tfidf_ngram_char)\n#     # assume that we don't have test set before\n#     X_test_tfidf_ngram_char_svd = svd_ngram_char.transform(X_test_tfidf_ngram_char)\n#     # C_2d_range = [1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9]\n#     # gamma_2d_range = [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2]\n#     # for C in C_2d_range:\n#     #     for gamma in gamma_2d_range:\n#     #         svm = SVC(kernel='rbf', random_state=1, C=C, gamma=gamma)\n#     #         svm.fit(X_data_tfidf_ngram_char_svd, y_data_n)\n#     #         y_pred_svm = svm.predict(X_test_tfidf_ngram_char_svd)\n#     #         print(\"c = %.9f , gamma = %.9f\" %(C,gamma))\n#     #         print(\"Accuracy of SVC: %.2f %%\" %(100*accuracy_score(y_test_n, y_pred_svm)))\n#     svm = SVC(kernel='rbf', random_state=1, gamma=0.1, C=10)\n#     svm.fit(X_data_tfidf_ngram_char_svd, y_data_n)\n#     y_pred_svm = svm.predict(X_test_tfidf_ngram_char_svd)\n#     print(\"n = %d\" %(n))\n#     print(\"Accuracy of KNN: %.2f %%\" %(100*accuracy_score(y_test_n, y_pred_svm)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n# C_2d_range = [1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9]\n# gamma_2d_range = [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2]\n# for C in C_2d_range:\n#     for gamma in gamma_2d_range:\n#         svm = SVC(kernel='rbf', random_state=1, C=C, gamma=gamma)\n#         svm.fit(X_data_tfidf_ngram_char_svd, y_data_n)\n#         y_pred_svm = svm.predict(X_test_tfidf_ngram_char_svd)\n#         print(\"c = %.9f , gamma = %.9f\" %(C,gamma))\n#         print(\"Accuracy of SVC: %.2f %%\" %(100*accuracy_score(y_test_n, y_pred_svm)))\nsvm = SVC(kernel='rbf', random_state=1, gamma=0.1, C=10)\nsvm.fit(X_data_tfidf_ngram_char_svd, y_data_n)\ny_pred_svm = svm.predict(X_test_tfidf_ngram_char_svd)\nprint(\"Accuracy of KNN: %.2f %%\" %(100*accuracy_score(y_test_n, y_pred_svm)))\n# C = 0.1, gamma = 1 => 82.41%\n# C = 1, gamma = 1 => 87.66%\n# C = 10, gamma = 0.1 => 87.91%\n# c = 100.000000000 , gamma = 0.010000000 Accuracy of SVC: 87.88 %\npickle.dump(svm, open('svm.pkl', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nregressor = RandomForestClassifier(n_estimators=1000, random_state=0)\nregressor.fit(X_data_tfidf_ngram_char_svd, y_data_n)\ny_pred_forest = regressor.predict(X_test_tfidf_ngram_char_svd)\nprint(\"Accuracy of Randomforest: %.2f %%\" %(100*accuracy_score(y_test_n, y_pred_forest)))\npickle.dump(regressor, open('RandomForestClassifier.pkl', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_real=[]\nroot_test_data = []\nwith open('../input/khaiphadulieutest/topic_detection_test_unlabel.v1.0.txt', 'r', encoding=\"utf-8\") as f:\n    for lines in f.readlines():\n        root_test_data.append(lines)\n        lines = gensim.utils.simple_preprocess(lines)\n#         lines = re.sub(r\"[^\\w\\d\\s]\",\" \",lines,flags=re.UNICODE)\n#         lines = re.sub(\"[0-9]\",\" \",lines,flags=re.UNICODE)\n#         lines = lines.split()\n        lines = ' '.join(lines)\n        lines = ViTokenizer.tokenize(lines)\n        X_test_real.append(lines)\npickle.dump(X_test_real, open('X_test_real.pkl', 'wb'))\nX_test_real_tfidf_ngram_char =  tfidf_vect_ngram_char.transform(X_test_real)\nX_test_real_tfidf_ngram_char_svd = svd_ngram_char.transform(X_test_real_tfidf_ngram_char)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVM\nsvm = pickle.load(open(\"svm.pkl\", 'rb'))\ny_pred = svm.predict(X_test_real_tfidf_ngram_char_svd)\nprint(y_pred[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"nhom1_TD_SOL2.txt\", mode=\"a\", encoding=\"utf-8\") as f:\n    for index in range(len(y_pred)):\n        f.write(encoder.classes_[y_pred[index]]+' '+root_test_data[index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# neighbors\nneighbors = pickle.load(open(\"neighbors.pkl\", 'rb'))\ny_pred_neighbors = neighbors.predict(X_test_real_tfidf_ngram_char_svd)\nprint(y_pred_neighbors[0])\nwith open(\"nhom1_TD_SOL3.txt\", mode=\"a\", encoding=\"utf-8\") as f:\n    for index in range(len(y_pred_neighbors)):\n        f.write(encoder.classes_[y_pred_neighbors[index]]+' '+root_test_data[index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LogisticRegression\nlogis = pickle.load(open(\"LogisticRegression.pkl\", 'rb'))\ny_pred_logis = logis.predict(X_test_real_tfidf_ngram_char_svd)\nprint(y_pred_logis[0])\nwith open(\"nhom1_TD_SOL4.txt\", mode=\"a\", encoding=\"utf-8\") as f:\n    for index in range(len(y_pred_logis)):\n        f.write(encoder.classes_[y_pred_logis[index]]+' '+root_test_data[index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LogisticRegression\nforest = pickle.load(open(\"RandomForestClassifier.pkl\", 'rb'))\ny_pred_forest = forest.predict(X_test_real_tfidf_ngram_char_svd)\nprint(y_pred_forest[0])\nwith open(\"nhom1_TD_SOL5.txt\", mode=\"a\", encoding=\"utf-8\") as f:\n    for index in range(len(y_pred_forest)):\n        f.write(encoder.classes_[y_pred_forest[index]]+' '+root_test_data[index])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}